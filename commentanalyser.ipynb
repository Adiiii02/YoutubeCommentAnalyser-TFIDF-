{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5577,"sourceType":"datasetVersion","datasetId":2518},{"sourceId":9801,"sourceType":"datasetVersion","datasetId":6763}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-02T16:36:13.451868Z","iopub.execute_input":"2024-03-02T16:36:13.452545Z","iopub.status.idle":"2024-03-02T16:36:13.470403Z","shell.execute_reply.started":"2024-03-02T16:36:13.452487Z","shell.execute_reply":"2024-03-02T16:36:13.469548Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin.gz\n/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\n/kaggle/input/youtube/GBvideos.csv\n/kaggle/input/youtube/UScomments.csv\n/kaggle/input/youtube/GB_category_id.json\n/kaggle/input/youtube/US_category_id.json\n/kaggle/input/youtube/GBcomments.csv\n/kaggle/input/youtube/USvideos.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import googleapiclient.discovery\n# import pandas as pd\n\n# api_service_name = \"youtube\"\n# api_version = \"v3\"\n# DEVELOPER_KEY = \"AIzaSyAS1qvkRUNvz1UOqBjUaVDRT21gPyuqF1M\"\n\n# youtube = googleapiclient.discovery.build(\n#     api_service_name, api_version, developerKey=DEVELOPER_KEY)\n\n# request = youtube.commentThreads().list(\n#     part=\"snippet\",\n#     videoId=\"KPLWWIOCOOQ\",\n#     maxResults=999\n# )\n# response = request.execute()\n\n# comments = []\n\n# for item in response['items']:\n#     comment = item['snippet']['topLevelComment']['snippet']\n#     comments.append([\n# #         comment['authorDisplayName'],\n# #         comment['publishedAt'],\n# #         comment['updatedAt'],\n# #         comment['likeCount'],\n#         comment['textDisplay']\n#     ])\n# # 'author', 'published_at', 'updated_at',\n# df = pd.DataFrame(comments, columns=['Comment'])\n\n# df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:14.714598Z","iopub.execute_input":"2024-03-02T16:36:14.714978Z","iopub.status.idle":"2024-03-02T16:36:14.720418Z","shell.execute_reply.started":"2024-03-02T16:36:14.714946Z","shell.execute_reply":"2024-03-02T16:36:14.719487Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_columns',None)\n\nUS_comments = pd.read_csv('../input/youtube/UScomments.csv', on_bad_lines='skip')\n\nGB_comments = pd.read_csv('/kaggle/input/youtube/GBcomments.csv', on_bad_lines='skip')\n\nUS_comments.head()\n\nGB_comments.head()\n\ndf1=US_comments['comment_text']\ndf2=GB_comments['comment_text']\n\nprint(df1.shape)\nprint(df2.shape)\n\ndf1=df1[:25000]\ndf2=df2[:25000]\n\ndf = pd.DataFrame(pd.concat([df1, df2]))\n\n# df=pd.DataFrame(df1)\n\nprint(df.shape)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:15.022544Z","iopub.execute_input":"2024-03-02T16:36:15.023201Z","iopub.status.idle":"2024-03-02T16:36:19.567888Z","shell.execute_reply.started":"2024-03-02T16:36:15.023171Z","shell.execute_reply":"2024-03-02T16:36:19.566779Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_26/3420677335.py:3: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n  US_comments = pd.read_csv('../input/youtube/UScomments.csv', on_bad_lines='skip')\n","output_type":"stream"},{"name":"stdout","text":"(691400,)\n(718452,)\n(50000, 1)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                        comment_text\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\n1  I've been following you from the start of your...\n2                 Say hi to Kong and maverick for me\n3                                MY FAN . attendance\n4                                         trending üòâ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.rename(columns = {'comment_text':'Comment'}, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:19.569549Z","iopub.execute_input":"2024-03-02T16:36:19.569840Z","iopub.status.idle":"2024-03-02T16:36:19.576653Z","shell.execute_reply.started":"2024-03-02T16:36:19.569814Z","shell.execute_reply":"2024-03-02T16:36:19.575598Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Libraries \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\n\n# Import functions for data preprocessing & data preparation\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nfrom string import punctuation\nimport nltk\nimport emoji\nimport re\n\n!pip install twython","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:19.577733Z","iopub.execute_input":"2024-03-02T16:36:19.578026Z","iopub.status.idle":"2024-03-02T16:36:34.951897Z","shell.execute_reply.started":"2024-03-02T16:36:19.578002Z","shell.execute_reply":"2024-03-02T16:36:34.950616Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"},{"name":"stdout","text":"Collecting twython\n  Obtaining dependency information for twython from https://files.pythonhosted.org/packages/db/08/9921df4cb5829858dbd580ebd8a5a4b9e75a0b8295bc1e98963a983a0621/twython-3.9.1-py3-none-any.whl.metadata\n  Downloading twython-3.9.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from twython) (2.31.0)\nRequirement already satisfied: requests-oauthlib>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from twython) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->twython) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->twython) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->twython) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->twython) (2023.11.17)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.4.0->twython) (3.2.2)\nDownloading twython-3.9.1-py3-none-any.whl (33 kB)\nInstalling collected packages: twython\nSuccessfully installed twython-3.9.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# data1=df.sort_values(by = 'like_count',ascending=False)\n# data1.head()\ndata1=df\ndata1.head()\n\n\nprint(data1.shape)\ndata1.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:34.955631Z","iopub.execute_input":"2024-03-02T16:36:34.956108Z","iopub.status.idle":"2024-03-02T16:36:34.968484Z","shell.execute_reply.started":"2024-03-02T16:36:34.956078Z","shell.execute_reply":"2024-03-02T16:36:34.967522Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(50000, 1)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             Comment\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\n1  I've been following you from the start of your...\n2                 Say hi to Kong and maverick for me\n3                                MY FAN . attendance\n4                                         trending üòâ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"nltk.download('vader_lexicon')\nsentiments = SentimentIntensityAnalyzer()\ndata1[\"Positive\"] = [sentiments.polarity_scores(str(i))[\"pos\"] for i in data1[\"Comment\"]]\ndata1[\"Negative\"] = [sentiments.polarity_scores(str(i))[\"neg\"] for i in data1[\"Comment\"]]\ndata1[\"Neutral\"] = [sentiments.polarity_scores(str(i))[\"neu\"] for i in data1[\"Comment\"]]\ndata1['Compound'] = [sentiments.polarity_scores(str(i))[\"compound\"] for i in data1[\"Comment\"]]\n\nscore = data1[\"Compound\"].values\nsentiment = []\nfor i in score:\n    if i >= 0.05 :\n        sentiment.append('Positive')\n    elif i <= -0.05 :\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndata1[\"Sentiment\"] = sentiment\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:36:34.969916Z","iopub.execute_input":"2024-03-02T16:36:34.970541Z","iopub.status.idle":"2024-03-02T16:37:24.209020Z","shell.execute_reply.started":"2024-03-02T16:36:34.970492Z","shell.execute_reply":"2024-03-02T16:37:24.208087Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Positive  Negative  \\\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è     0.000       0.0   \n1  I've been following you from the start of your...     0.000       0.0   \n2                 Say hi to Kong and maverick for me     0.000       0.0   \n3                                MY FAN . attendance     0.603       0.0   \n4                                         trending üòâ     0.000       0.0   \n\n   Neutral  Compound Sentiment  \n0    1.000    0.0000   Neutral  \n1    1.000    0.0000   Neutral  \n2    1.000    0.0000   Neutral  \n3    0.397    0.4648  Positive  \n4    1.000    0.0000   Neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Compound</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n      <td>0.603</td>\n      <td>0.0</td>\n      <td>0.397</td>\n      <td>0.4648</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:24.210235Z","iopub.execute_input":"2024-03-02T16:37:24.210580Z","iopub.status.idle":"2024-03-02T16:37:24.229017Z","shell.execute_reply.started":"2024-03-02T16:37:24.210554Z","shell.execute_reply":"2024-03-02T16:37:24.228062Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                             Comment Sentiment\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è   Neutral\n1  I've been following you from the start of your...   Neutral\n2                 Say hi to Kong and maverick for me   Neutral\n3                                MY FAN . attendance  Positive\n4                                         trending üòâ   Neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:24.230028Z","iopub.execute_input":"2024-03-02T16:37:24.230302Z","iopub.status.idle":"2024-03-02T16:37:24.244783Z","shell.execute_reply.started":"2024-03-02T16:37:24.230279Z","shell.execute_reply":"2024-03-02T16:37:24.243926Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def text_processing(text):   \n    # convert text into lowercase\n    text = text.lower()\n\n    # remove new line characters in text\n    text = re.sub(r'\\n',' ', text)\n    \n    # remove punctuations from text\n    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n    \n    # remove references and hashtags from text\n    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n    \n    # remove multiple spaces from text\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    \n    # remove special characters from text\n    text = re.sub(r'\\W', ' ', text)\n    \n    emoji.demojize(text)\n\n    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:24.245870Z","iopub.execute_input":"2024-03-02T16:37:24.246182Z","iopub.status.idle":"2024-03-02T16:37:24.253921Z","shell.execute_reply.started":"2024-03-02T16:37:24.246158Z","shell.execute_reply":"2024-03-02T16:37:24.252974Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# nltk.download('omw-1.4')\ndata_copy = data2.copy()\ndata_copy.Comment = data_copy.Comment.apply(lambda text: text_processing(str(text)))\n\ndata_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:24.254972Z","iopub.execute_input":"2024-03-02T16:37:24.255228Z","iopub.status.idle":"2024-03-02T16:37:45.100812Z","shell.execute_reply.started":"2024-03-02T16:37:24.255206Z","shell.execute_reply":"2024-03-02T16:37:45.099830Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                           Comment Sentiment\n0                            logan paul yo big day   Neutral\n1  ive following start vine channel seen 365 vlogs   Neutral\n2                             say hi kong maverick   Neutral\n3                                   fan attendance  Positive\n4                                         trending   Neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>logan paul yo big day</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ive following start vine channel seen 365 vlogs</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>say hi kong maverick</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fan attendance</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"le = LabelEncoder()\ndata_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])\ndata_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.105389Z","iopub.execute_input":"2024-03-02T16:37:45.105791Z","iopub.status.idle":"2024-03-02T16:37:45.129154Z","shell.execute_reply.started":"2024-03-02T16:37:45.105762Z","shell.execute_reply":"2024-03-02T16:37:45.128281Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                           Comment  Sentiment\n0                            logan paul yo big day          1\n1  ive following start vine channel seen 365 vlogs          1\n2                             say hi kong maverick          1\n3                                   fan attendance          2\n4                                         trending          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>logan paul yo big day</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ive following start vine channel seen 365 vlogs</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>say hi kong maverick</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fan attendance</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"processed_data = {\n    'Sentence':data_copy.Comment,\n    'Sentiment':data_copy['Sentiment'],\n#     'Likes':data_copy['like_count']\n}\n\nprocessed_data = pd.DataFrame(processed_data)\nprocessed_data.head(20)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.130455Z","iopub.execute_input":"2024-03-02T16:37:45.130858Z","iopub.status.idle":"2024-03-02T16:37:45.144553Z","shell.execute_reply.started":"2024-03-02T16:37:45.130821Z","shell.execute_reply":"2024-03-02T16:37:45.143639Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                             Sentence  Sentiment\n0                               logan paul yo big day          1\n1     ive following start vine channel seen 365 vlogs          1\n2                                say hi kong maverick          1\n3                                      fan attendance          2\n4                                            trending          1\n5                                 1 trending ayyeeeee          1\n6                                          end though          1\n7                                          1 trending          1\n8                         happy one year vlogaversary          2\n9   shit brother may single handedly ruined youtub...          0\n10                                    mini logan paul          1\n11  dear logan really wan na get merch dont money ...          2\n12  honestly evan annoying like funny watching try...          0\n13                           casey still better logan          2\n14                      aw geez rick guy face youtube          1\n15                                  happy cause movie          2\n16  ayyyyoooo logang hard vlog watch logan dare de...          2\n17           bro didnt u give merch johannes ur boy 2          1\n18  fun watching grow im 42 days straight cant see...          2\n19                    made lot people hate youtube gj          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>logan paul yo big day</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ive following start vine channel seen 365 vlogs</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>say hi kong maverick</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fan attendance</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1 trending ayyeeeee</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>end though</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1 trending</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>happy one year vlogaversary</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>shit brother may single handedly ruined youtub...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>mini logan paul</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>dear logan really wan na get merch dont money ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>honestly evan annoying like funny watching try...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>casey still better logan</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>aw geez rick guy face youtube</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>happy cause movie</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ayyyyoooo logang hard vlog watch logan dare de...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>bro didnt u give merch johannes ur boy 2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>fun watching grow im 42 days straight cant see...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>made lot people hate youtube gj</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"processed_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.145734Z","iopub.execute_input":"2024-03-02T16:37:45.146080Z","iopub.status.idle":"2024-03-02T16:37:45.166530Z","shell.execute_reply.started":"2024-03-02T16:37:45.146056Z","shell.execute_reply":"2024-03-02T16:37:45.165736Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Sentiment\n2    23036\n1    17134\n0     9830\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_neutral = processed_data[(processed_data['Sentiment']==1)] \ndf_negative = processed_data[(processed_data['Sentiment']==0)]\ndf_positive = processed_data[(processed_data['Sentiment']==2)]\n\n# # upsample minority classes\n# df_negative_upsampled = resample(df_negative, \n#                                  replace=True,    \n#                                  n_samples= 300, \n#                                  random_state=42)  \n\n# df_neutral_upsampled = resample(df_neutral, \n#                                  replace=True,    \n#                                  n_samples= 300, \n#                                  random_state=42)  \n\n# df_positive_upsampled = resample(df_positive, \n#                                  replace=False,    \n#                                  n_samples= 13716, \n#                                  random_state=42)  \n\n# df_neutral_upsampled = resample(df_neutral, \n#                                  replace=False,    \n#                                  n_samples= 13716, \n#                                  random_state=42) \n\n\n# Concatenate the upsampled dataframes with the neutral dataframe\n# final_data = pd.concat([df_negative,df_neutral_upsampled,df_positive_upsampled])\n\nfinal_data=processed_data","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.167756Z","iopub.execute_input":"2024-03-02T16:37:45.168155Z","iopub.status.idle":"2024-03-02T16:37:45.184391Z","shell.execute_reply.started":"2024-03-02T16:37:45.168125Z","shell.execute_reply":"2024-03-02T16:37:45.183559Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"final_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.185496Z","iopub.execute_input":"2024-03-02T16:37:45.185814Z","iopub.status.idle":"2024-03-02T16:37:45.193329Z","shell.execute_reply.started":"2024-03-02T16:37:45.185791Z","shell.execute_reply":"2024-03-02T16:37:45.192482Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Sentiment\n2    23036\n1    17134\n0     9830\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"corpus = []\nfor sentence in final_data['Sentence']:\n    corpus.append(sentence)\ncorpus[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.194558Z","iopub.execute_input":"2024-03-02T16:37:45.194935Z","iopub.status.idle":"2024-03-02T16:37:45.215864Z","shell.execute_reply.started":"2024-03-02T16:37:45.194901Z","shell.execute_reply":"2024-03-02T16:37:45.215034Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['logan paul yo big day',\n 'ive following start vine channel seen 365 vlogs',\n 'say hi kong maverick',\n 'fan attendance',\n 'trending']"},"metadata":{}}]},{"cell_type":"code","source":"# from sklearn.feature_extraction.text import CountVectorizer\n# cv = CountVectorizer(max_features=400,binary=True,ngram_range=(1,5))\n# X = cv.fit_transform(corpus).toarray()\n# y = final_data.iloc[:, -1].values\n# # X.shape__sizeof__","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:37:45.216933Z","iopub.execute_input":"2024-03-02T16:37:45.217223Z","iopub.status.idle":"2024-03-02T16:37:45.225022Z","shell.execute_reply.started":"2024-03-02T16:37:45.217191Z","shell.execute_reply":"2024-03-02T16:37:45.224234Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntf=TfidfVectorizer(max_features=6000,binary=True,ngram_range=(1,6))\nX = tf.fit_transform(corpus).toarray()\ny = final_data.iloc[:, -1].values\n# print(X)\n# X.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:02:33.061936Z","iopub.execute_input":"2024-03-02T17:02:33.062329Z","iopub.status.idle":"2024-03-02T17:02:40.458485Z","shell.execute_reply.started":"2024-03-02T17:02:33.062298Z","shell.execute_reply":"2024-03-02T17:02:40.456971Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest=RandomForestClassifier()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n# classifier = GaussianNB()\n# classifier.fit(X_train, y_train)\nforest.fit(X_train,y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:02:40.460941Z","iopub.execute_input":"2024-03-02T17:02:40.461306Z","iopub.status.idle":"2024-03-02T17:11:02.478703Z","shell.execute_reply.started":"2024-03-02T17:02:40.461281Z","shell.execute_reply":"2024-03-02T17:11:02.477748Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier()","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\n# y_pred = classifier.predict(X_test)\n# y_pre = classifier.predict(X_train)\ny_preds=forest.predict(X_test)\n# cm = confusion_matrix(y_test, y_pred)\ncm1 = confusion_matrix(y_test, y_preds)\n# print(cm)\nprint(cm1)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:11:02.480003Z","iopub.execute_input":"2024-03-02T17:11:02.480383Z","iopub.status.idle":"2024-03-02T17:11:06.724395Z","shell.execute_reply.started":"2024-03-02T17:11:02.480342Z","shell.execute_reply":"2024-03-02T17:11:06.723506Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[[2176  279  567]\n [  85 4813  248]\n [ 113  269 6450]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# nb_score = accuracy_score(y_test, y_pred)\n# nb_score = accuracy_score(y_train, y_train)\nnb_score1 = accuracy_score(y_test, y_preds)\n# print('accuracy',nb_score)\nprint('accuracy',nb_score1)\nprint(y_preds.shape)\ny_preds.shape\n# print(y_pre)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:11:06.726206Z","iopub.execute_input":"2024-03-02T17:11:06.726500Z","iopub.status.idle":"2024-03-02T17:11:06.734862Z","shell.execute_reply.started":"2024-03-02T17:11:06.726475Z","shell.execute_reply":"2024-03-02T17:11:06.733863Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"accuracy 0.8959333333333334\n(15000,)\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(15000,)"},"metadata":{}}]},{"cell_type":"code","source":"# import pickle \n# pickle.dump(forest,open('forest.pkl','wb'))","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:58:32.098731Z","iopub.execute_input":"2024-03-02T16:58:32.099015Z","iopub.status.idle":"2024-03-02T16:58:32.103249Z","shell.execute_reply.started":"2024-03-02T16:58:32.098992Z","shell.execute_reply":"2024-03-02T16:58:32.102235Z"},"trusted":true},"execution_count":29,"outputs":[]}]}